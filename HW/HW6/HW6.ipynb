{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBt9GzsX/vMlRBUljd9xyp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/ECE-GY9123_DL/blob/main/HW/HW6/HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxK7qvDM6s2z"
      },
      "source": [
        "## A simple GAN\n",
        "In this problem, the goal is to train and visualize the outputs of a simple Deep\n",
        "Convolutional GAN (DCGAN) to generate realistic-looking (but fake) images of clothing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbTWxpoC6-mj"
      },
      "source": [
        "* a. Use the FashionMNIST training dataset to train the DCGAN. APIs for downloading it\n",
        "are available in both PyTorch and TensorFlow. Images are grayscale and size 28 × 28.\n",
        "* b. Use the following discriminator architecture (kernel size = 5 × 5 with stride = 2 in both\n",
        "directions):\n",
        "** 2D convolutions (1 × 28 × 28 → 64 × 14 × 14 → 128 × 7 × 7)\n",
        "** each convolutional layer is equipped with a Leaky ReLU with slope 0.3, followed\n",
        "by Dropout with parameter 0.3.\n",
        "** a dense layer that takes the flattened output of the last convolution and maps it to a\n",
        "scalar.\n",
        "\n",
        "Here is a [link](https://discuss.pytorch.org/t/how-to-keep-the-shape-of-input-and-output-same-when-dilation-conv/14338/3) that discusses how to appropriately choose padding and stride values in order to\n",
        "desired sizes.\n",
        "\n",
        "* c. Use the following generator architecture (which is essentially the reverse of a standard\n",
        "discriminative architecture). You can use the same kernel size. Construct:\n",
        "** a dense layer that takes a unit Gaussian noise vector of length 100 and maps it to a\n",
        "vector of size 7 ∗ 7 ∗ 256. No bias terms.\n",
        "** several transpose 2D convolutions (256 × 7 × 7 → 128 × 7 × 7 → 64 × 14 × 14 →\n",
        "1 × 28 × 28). No bias terms.\n",
        "** each convolutional layer (except the last one) is equipped with Batch Normalization\n",
        "(batch norm), followed by Leaky ReLU with slope 0.3. The last (output) layer is\n",
        "equipped with tanh activation (no batch norm).\n",
        "* d. Use the cross-entropy loss for training both the generator and the discriminator. Use the\n",
        "Adam optimizer with learning rate $10^{-4}$. \n",
        "* e. Train it for 50 epochs. You can use minibatch sizes of 16, 32, or 64. Training may take\n",
        "several minutes (or even up to an hour), so be patient! Display intermediate images\n",
        "generated after T = 10, T = 30, and T = 50 epochs. If the random seeds are fixed\n",
        "throughout then you should get results of the following quality.\n",
        "![WeChat Screenshot_20210501224441](https://user-images.githubusercontent.com/68700549/116800418-dcd71480-aace-11eb-9f80-41f4ede3ec0c.png)\n",
        "* f. Report loss curves for both the discriminator and the generator loss over all epochs, and\n",
        "qualitatively comment on their behavior.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://github.com/bissessk/DCGANs-to-Generate-Clothing-Images-Using-Fashion-MNIST/blob/main/DCGANsFashionMnist.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF6BljYF-D0w"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pirS2cNH6nM0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}