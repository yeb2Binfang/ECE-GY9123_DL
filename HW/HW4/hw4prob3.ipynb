{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4prob3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e7bc9e488de4d6bbf522112ba9fe86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d278bd39a894513ba853694142ca9e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_67586f7ae69a4cf6b2c5c3ae2ca63fe6",
              "IPY_MODEL_1606c3073e0041ca945c7d49306708b0"
            ]
          }
        },
        "3d278bd39a894513ba853694142ca9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67586f7ae69a4cf6b2c5c3ae2ca63fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f5bdea3272340828126aaf70a54fc0e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3825deb7a9d549cf80655484397aef83"
          }
        },
        "1606c3073e0041ca945c7d49306708b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c42c2c46e45449c99afe85e5aef357dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 1.34MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b054973e6ea548f79cf35b0572a66e99"
          }
        },
        "3f5bdea3272340828126aaf70a54fc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3825deb7a9d549cf80655484397aef83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c42c2c46e45449c99afe85e5aef357dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b054973e6ea548f79cf35b0572a66e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4689272b155a448a9686777dac054e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_afa2cac8b0b44d1ca56de03efae3ac15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a03e7ff5702460b9448d8d0a2ac46ac",
              "IPY_MODEL_a2b50c43b5ef4e7fb8576d4590e9aec5"
            ]
          }
        },
        "afa2cac8b0b44d1ca56de03efae3ac15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a03e7ff5702460b9448d8d0a2ac46ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d8a75927ed14addafdd586fe7837bbf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53428fb5a934458c93e24ce3a2032839"
          }
        },
        "a2b50c43b5ef4e7fb8576d4590e9aec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61fb839f2fcf4d7d9b3de542e4a7654c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.06kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba46a3aefc8b48e1bc8e5faa6256605c"
          }
        },
        "3d8a75927ed14addafdd586fe7837bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53428fb5a934458c93e24ce3a2032839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61fb839f2fcf4d7d9b3de542e4a7654c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba46a3aefc8b48e1bc8e5faa6256605c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1065c9dadcf47a4b4786727db3d9d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1096d944e8094c65a34471f5857114df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7901842adc3d48b1ab1b69f5652ad79a",
              "IPY_MODEL_c516b77159f3406eb24d870655791cdf"
            ]
          }
        },
        "1096d944e8094c65a34471f5857114df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7901842adc3d48b1ab1b69f5652ad79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f51f01bdd9af4676a8dab1bdf6b7b305",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_986e584527d64fa3a62ccc2f116f59df"
          }
        },
        "c516b77159f3406eb24d870655791cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c76d8d5f47fe403b8eb42ff2df7b5fda",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:51&lt;00:00, 8.50MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bbe87b17cef41249f297d909e733c29"
          }
        },
        "f51f01bdd9af4676a8dab1bdf6b7b305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "986e584527d64fa3a62ccc2f116f59df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c76d8d5f47fe403b8eb42ff2df7b5fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bbe87b17cef41249f297d909e733c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/ECE-GY9123_DL/blob/main/HW/HW4/hw4prob3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8047778-7676-452f-cbf9-88091c12ee00"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.10\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.8.1+cu101\n",
            "transformers: 2.8.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91986e92-3f5c-4375-9645-bff99c9f8c74"
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 39.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 63.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ofiNmneqeP"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "80db5125-a53e-4396-85ba-f1ad7da477aa"
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiAdQ3j6SDe"
      },
      "source": [
        "Let's first check the size of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c78508-905b-452a-a872-bbacb3784b89"
      },
      "source": [
        "# TODO: Q1. How many samples are there in this dataset? \n",
        "# There are 15746 samples in this dataset\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "99217d36-3dd9-4f9a-94be-676b714535ad"
      },
      "source": [
        "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
        "# we can see that the score of 3 has the most.\n",
        "sns.histplot(data=df['score'],discrete=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1a0ffa2210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk7C5tkJjMiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4292a5-3677-4188-9964-0e6f22cef868"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    5676\n",
              "1    5042\n",
              "0    5028\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']\n",
        "vals = [5028,5042,5676]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b5d6f4c9-9db5-472a-9a2d-720f45cbbd3c"
      },
      "source": [
        "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
        "sns.barplot(x=class_names,y=vals)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7740e65810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqJdhZHClST1",
        "outputId": "df07e424-9975-44f4-daff-042f952c2854"
      },
      "source": [
        "pip install transformers==2.8.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 25.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 18.7MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/19/20a0d00e8cd7b812aaf408ce512c7ad41fc0bca4a2206674e9d6bc0c058d/boto3-1.17.43.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Collecting botocore<1.21.0,>=1.20.43\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/a5/72893a964c4c97920e3ae1c1adb37905409aa1492345767583adf3ee10ed/botocore-1.20.43-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 52.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.43->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses, boto3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=95b9b51740e4963723a94dcc6d860a4ec084851da9da2e0b74ba905cb0a2ceb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.17.43-py2.py3-none-any.whl size=128778 sha256=2ce07a6b623cc09902a2f937cfb30b1604d999f2b335634060674fcd33e9ba21\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/b4/95/0327754601f89dfdae855ca2280bdaf249e625afd0ef17a4a3\n",
            "Successfully built sacremoses boto3\n",
            "\u001b[31mERROR: botocore 1.20.43 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.17.43 botocore-1.20.43 jmespath-0.10.0 s3transfer-0.3.6 sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLO3XSwSkmon"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7e7bc9e488de4d6bbf522112ba9fe86e",
            "3d278bd39a894513ba853694142ca9e3",
            "67586f7ae69a4cf6b2c5c3ae2ca63fe6",
            "1606c3073e0041ca945c7d49306708b0",
            "3f5bdea3272340828126aaf70a54fc0e",
            "3825deb7a9d549cf80655484397aef83",
            "c42c2c46e45449c99afe85e5aef357dc",
            "b054973e6ea548f79cf35b0572a66e99"
          ]
        },
        "outputId": "66586c67-8976-410d-8ad3-54ac87ac631a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e7bc9e488de4d6bbf522112ba9fe86e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0ca3d7-471c-474f-c925-2c8d90f96e26"
      },
      "source": [
        "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
        "print(tokenizer.tokenize(sample_txt))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample_txt)))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449a3bbe-d8a8-40e5-9885-6861e80aa09f"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3defb4a-0c23-47d6-8ffb-98b390e0aea3"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fca140b-08b9-44b0-cf82-b09cc01d612c"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b57d31-1d00-4722-eda8-9706b998e8b4"
      },
      "source": [
        "# TODO: Q5. Invert the encoded token ids.\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Every',\n",
              " 'day',\n",
              " 'feels',\n",
              " 'like',\n",
              " 'the',\n",
              " 'same',\n",
              " 'during',\n",
              " 'the',\n",
              " 'lock',\n",
              " 'down',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FssUpW7O7r3E"
      },
      "source": [
        " from torch.utils.data import Dataset"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrxjZ0meZ53"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEO5P7aPnD50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ce4ed8-67d9-4485-ea90-0c5cb786d1d0"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO"
      },
      "source": [
        "# TODO: Q6. Create three data frames: df_train, df_val, df_test as above and print their shapes.\n",
        "df_train, test_val = train_test_split(df, test_size=0.1, random_state = 42, shuffle=True)\n",
        "df_val, df_test = train_test_split(test_val, test_size=0.5,random_state = 42, shuffle=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1n6rbTnhpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b3e6a8-d500-4676-df18-1f4f567ba068"
      },
      "source": [
        "print(df_train.describe)\n",
        "print(df_val.describe)\n",
        "print(df_test.describe)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "1562               Raspiy  ...         0\n",
            "15084        Ebony Sealey  ...         1\n",
            "7417   Iindin the Edresia  ...         1\n",
            "12044        Hydee Fisher  ...         1\n",
            "12410       Tanya Ruppell  ...         0\n",
            "...                   ...  ...       ...\n",
            "5191            Mamatha t  ...         0\n",
            "13418             chi mak  ...         0\n",
            "5390      bhawna shraddha  ...         1\n",
            "860       Adrian Anderson  ...         2\n",
            "7270          Alec Machet  ...         0\n",
            "\n",
            "[14171 rows x 12 columns]>\n",
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "1402                Chris  ...         0\n",
            "850          Morhaf Osama  ...         2\n",
            "11028        Girish Palve  ...         0\n",
            "1655         Mauri Galvez  ...         1\n",
            "14287  Jennifer V Mendoza  ...         2\n",
            "...                   ...  ...       ...\n",
            "7234        sventhedog gy  ...         0\n",
            "15641    Arvind Ramshetty  ...         2\n",
            "101          Joe Joejambo  ...         0\n",
            "2342       Janne Uusitalo  ...         2\n",
            "11438  SINGER Somya Yadav  ...         1\n",
            "\n",
            "[787 rows x 12 columns]>\n",
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "6550         Robert Sevin  ...         1\n",
            "14101  Paradoxtal Pythons  ...         1\n",
            "7447        Daniel Whited  ...         1\n",
            "2150                xeigh  ...         2\n",
            "11292  SINGER Somya Yadav  ...         1\n",
            "...                   ...  ...       ...\n",
            "8221         Avesta Irani  ...         2\n",
            "4885            meow meow  ...         0\n",
            "4115      Lucinda Sanchez  ...         1\n",
            "4693          Joshua Choo  ...         2\n",
            "12577            Monica J  ...         1\n",
            "\n",
            "[788 rows x 12 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmPCamhcsr0d"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df24c99-887d-45d3-f543-cbf28a4d7948"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGVrAPSTs61N"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec66b65-f8a7-441f-caa2-c584d7b22300"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "4689272b155a448a9686777dac054e8e",
            "afa2cac8b0b44d1ca56de03efae3ac15",
            "3a03e7ff5702460b9448d8d0a2ac46ac",
            "a2b50c43b5ef4e7fb8576d4590e9aec5",
            "3d8a75927ed14addafdd586fe7837bbf",
            "53428fb5a934458c93e24ce3a2032839",
            "61fb839f2fcf4d7d9b3de542e4a7654c",
            "ba46a3aefc8b48e1bc8e5faa6256605c",
            "f1065c9dadcf47a4b4786727db3d9d5d",
            "1096d944e8094c65a34471f5857114df",
            "7901842adc3d48b1ab1b69f5652ad79a",
            "c516b77159f3406eb24d870655791cdf",
            "f51f01bdd9af4676a8dab1bdf6b7b305",
            "986e584527d64fa3a62ccc2f116f59df",
            "c76d8d5f47fe403b8eb42ff2df7b5fda",
            "4bbe87b17cef41249f297d909e733c29"
          ]
        },
        "outputId": "bb717da1-29bf-42d1-9386-a9bf822f134f"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4689272b155a448a9686777dac054e8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1065c9dadcf47a4b4786727db3d9d5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7TPDTSvTVU"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae7849c-8107-4629-dbeb-475776dd06c1"
      },
      "source": [
        "# TODO: Q7. Print the sizes of the hidden states and the pooled output.\n",
        "print(last_hidden_state.size())\n",
        "\n",
        "print(pooled_output.size())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 768])\n",
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "device = torch.device('cuda:0')\n",
        "model = model.to(device)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry"
      },
      "source": [
        "outputs1 = model(\n",
        "  input_ids=input_ids,\n",
        "  attention_mask=attention_mask\n",
        ")\n",
        "prob = F.softmax(outputs1, dim=1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNw3sR1wnk3I",
        "outputId": "9a4f1352-ece4-490b-8408-09dd816825b4"
      },
      "source": [
        "print(outputs1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8036, -0.0667,  0.2384],\n",
            "        [ 0.5499,  0.4858, -0.0507],\n",
            "        [ 0.4662,  0.3497, -0.1027],\n",
            "        [ 0.5791,  0.2475, -0.1871],\n",
            "        [ 0.8534,  0.2436,  0.4002],\n",
            "        [ 0.5620,  0.3253,  0.2839],\n",
            "        [ 0.3429, -0.1134,  0.3472],\n",
            "        [ 0.6116,  0.1117, -0.1785],\n",
            "        [ 0.7330,  0.2370,  0.2766],\n",
            "        [ 0.8563,  0.2086,  0.3081],\n",
            "        [ 0.4379,  0.2441,  0.1245],\n",
            "        [ 0.7415,  0.1494, -0.3459],\n",
            "        [ 0.4121,  0.0639, -0.0375],\n",
            "        [ 0.6646,  0.5053,  0.2297],\n",
            "        [ 0.3990, -0.1190, -0.0300],\n",
            "        [ 0.3602,  0.2597, -0.1292]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELFgUQuQv9vK"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
        "    \n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += 1\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += 1\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkeEdYmRr0Zx"
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "b16e6cbe-2e09-4e8e-fb9f-b35be3c43922"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model,train_data_loader,loss_fn,optimizer,device,scheduler,len(train_data_loader))\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(model,val_data_loader,loss_fn,device,len(val_data_loader))\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-df9471f3b1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nhistory = defaultdict(list)\\nbest_accuracy = 0\\n\\nfor epoch in range(EPOCHS):\\n\\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\\n  print('-' * 10)\\n\\n  # TODO: Q10. Complete the code below to track train and test accuracy.losses\\n\\n  train_acc, train_loss = train_epoch(model,train_data_loader,loss_fn,optimizer,device,scheduler,len(train_data_loader))\\n\\n  print(f'Train loss {train_loss} accuracy {train_acc}')\\n\\n  val_acc, val_loss = eval_model(model,val_data_loader,loss_fn,device,len(val_data_loader))\\n\\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\\n  print()\\n\\n  history['train_acc'].append(train_acc)\\n  history['train_loss'].append(train_loss)\\n  history['val_acc'].append(val_acc)\\n  history['val_loss'].append(val_loss)\\n\\n  if val_acc > best_accuracy:\\n    torch.save(model.state_dict(), 'best_model_state.bin')\\n    best_accuracy = val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-16516d8a7df5>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'double'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V"
      },
      "source": [
        "# TODO: Q11. Plot train/validation accuracies.\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh"
      },
      "source": [
        "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr"
      },
      "source": [
        "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}