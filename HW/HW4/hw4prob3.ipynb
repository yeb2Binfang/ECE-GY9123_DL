{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4prob3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0337f1b3cc0497a9f028cd7cb925c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3383afdc227f4c1c8d79f22105926ca7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd35475203dc41efab3437a5117787a8",
              "IPY_MODEL_193569ba5719478b9b9e991b3820257a"
            ]
          }
        },
        "3383afdc227f4c1c8d79f22105926ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd35475203dc41efab3437a5117787a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc51a5e0402e400594bcecaa9c7e28d6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e18368e51bd946a0960608d1b16538b3"
          }
        },
        "193569ba5719478b9b9e991b3820257a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7d96ec7fe654333bf0417b51a4e1eb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 686kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dce78d20306430db1971bf7c9f2acb8"
          }
        },
        "bc51a5e0402e400594bcecaa9c7e28d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e18368e51bd946a0960608d1b16538b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7d96ec7fe654333bf0417b51a4e1eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dce78d20306430db1971bf7c9f2acb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fbb1a5fa9ac4cab9ab1c9ffb0885bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb75e9840d8e449898b97ef67b436a7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32689e42fe67425589b725df1e447774",
              "IPY_MODEL_66e11e6546f64e408d205bf17e7339f6"
            ]
          }
        },
        "eb75e9840d8e449898b97ef67b436a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32689e42fe67425589b725df1e447774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a6fb2417a644d0cb83d48ed65edc709",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e83185dd474349589eb0bf95ffb1cad0"
          }
        },
        "66e11e6546f64e408d205bf17e7339f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae4adc69d26d4e9e90485ddf05a27b98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:11&lt;00:00, 38.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcbd208ab4054e89ac7bd80fb290ab86"
          }
        },
        "0a6fb2417a644d0cb83d48ed65edc709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e83185dd474349589eb0bf95ffb1cad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae4adc69d26d4e9e90485ddf05a27b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcbd208ab4054e89ac7bd80fb290ab86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1d12e33408d4197884401c2bb5ad75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b10f583053254aac81d598a844132afa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09cb1bb65f1942369c5c10578d497c25",
              "IPY_MODEL_ea91a00fa88a42ccb4fcc8f11d737d84"
            ]
          }
        },
        "b10f583053254aac81d598a844132afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09cb1bb65f1942369c5c10578d497c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bef3f93d32ca4dcbb87409e3643ef137",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb950df6f61d4ba3bdfc1acd5d1fdba5"
          }
        },
        "ea91a00fa88a42ccb4fcc8f11d737d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06f2f29f4b274f74abce5a2c68b84f84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:10&lt;00:00, 41.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_248adcd92e8043179c77ca7c38232f57"
          }
        },
        "bef3f93d32ca4dcbb87409e3643ef137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb950df6f61d4ba3bdfc1acd5d1fdba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06f2f29f4b274f74abce5a2c68b84f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "248adcd92e8043179c77ca7c38232f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/ECE-GY9123_DL/blob/main/HW/HW4/hw4prob3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ad4236-68b0-4cb1-c39a-2635367c8232"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.10\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.8.1+cu101\n",
            "transformers: 2.8.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc2c862-8f65-48d4-8aa2-935230e684a9"
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 48.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 112MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ofiNmneqeP"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "d395167d-e78c-4d01-b3c2-7650dc9967d5"
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars PanzerbjÃ¸rn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars PanzerbjÃ¸rn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiAdQ3j6SDe"
      },
      "source": [
        "Let's first check the size of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1234aa00-8835-49c5-f86b-1252899b633d"
      },
      "source": [
        "# TODO: Q1. How many samples are there in this dataset? \n",
        "# There are 15746 samples in this dataset\n",
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "1ca8f89c-c09b-4a22-f958-9a4cabbfef36"
      },
      "source": [
        "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
        "# we can see that the score of 3 has the most.\n",
        "sns.countplot(df['score'])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b5e91d9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk7C5tkJjMiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c91320b-8740-4e3a-ef64-4328d62d2659"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    5676\n",
              "1    5042\n",
              "0    5028\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']\n",
        "vals = [5028,5042,5676]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f67e6787-a471-4ff2-989a-31e89e3432ba"
      },
      "source": [
        "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
        "sns.barplot(x=class_names,y=vals)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1caecbba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "sqJdhZHClST1",
        "outputId": "e49efaed-9e8b-4ddc-8f5a-0ab01b46e9eb"
      },
      "source": [
        "pip install transformers==2.8.0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.43)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/19/20a0d00e8cd7b812aaf408ce512c7ad41fc0bca4a2206674e9d6bc0c058d/boto3-1.17.43.tar.gz (99kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.6MB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Collecting botocore<1.21.0,>=1.20.43\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/a5/72893a964c4c97920e3ae1c1adb37905409aa1492345767583adf3ee10ed/botocore-1.20.43-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.4MB 55.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.43->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: boto3\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.17.43-py2.py3-none-any.whl size=128778 sha256=66f2c57bf6374c69573857b06241bc72f7380014ceaa6e999c3cc376206346ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/b4/95/0327754601f89dfdae855ca2280bdaf249e625afd0ef17a4a3\n",
            "Successfully built boto3\n",
            "\u001b[31mERROR: botocore 1.20.43 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, jmespath, botocore, s3transfer, boto3, tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.10.1\n",
            "    Uninstalling tokenizers-0.10.1:\n",
            "      Successfully uninstalled tokenizers-0.10.1\n",
            "  Found existing installation: transformers 4.4.2\n",
            "    Uninstalling transformers-4.4.2:\n",
            "      Successfully uninstalled transformers-4.4.2\n",
            "Successfully installed boto3-1.17.43 botocore-1.20.43 jmespath-0.10.0 s3transfer-0.3.6 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLO3XSwSkmon"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d0337f1b3cc0497a9f028cd7cb925c3a",
            "3383afdc227f4c1c8d79f22105926ca7",
            "bd35475203dc41efab3437a5117787a8",
            "193569ba5719478b9b9e991b3820257a",
            "bc51a5e0402e400594bcecaa9c7e28d6",
            "e18368e51bd946a0960608d1b16538b3",
            "c7d96ec7fe654333bf0417b51a4e1eb5",
            "3dce78d20306430db1971bf7c9f2acb8"
          ]
        },
        "outputId": "b443e1dc-ff4d-40d3-a255-2c24598c439d"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0337f1b3cc0497a9f028cd7cb925c3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ed53a8-1eab-47ee-d225-198b01a1b8ad"
      },
      "source": [
        "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
        "print(tokenizer.tokenize(sample_txt))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample_txt)))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e73aeff-75b5-47d2-e3a9-55c304f20f8c"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ad6520-07d8-42bb-d9ad-1d79800b13a1"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82856b87-b94d-4626-dc60-8927028e145b"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654ebe3b-0f3f-4ddf-f17a-d1826f1cfb9c"
      },
      "source": [
        "# TODO: Q5. Invert the encoded token ids.\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Every',\n",
              " 'day',\n",
              " 'feels',\n",
              " 'like',\n",
              " 'the',\n",
              " 'same',\n",
              " 'during',\n",
              " 'the',\n",
              " 'lock',\n",
              " 'down',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FssUpW7O7r3E"
      },
      "source": [
        " from torch.utils.data import Dataset"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrxjZ0meZ53"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEO5P7aPnD50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18ca2af-68c2-4e7e-c1f2-4d63b551dde4"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO"
      },
      "source": [
        "# TODO: Q6. Create three data frames: df_train, df_val, df_test as above and print their shapes.\n",
        "df_train, test_val = train_test_split(df, test_size=0.1, random_state = 42, shuffle=True)\n",
        "df_val, df_test = train_test_split(test_val, test_size=0.5,random_state = 42, shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1n6rbTnhpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d33b97a-7277-4a59-d819-d353cef4a557"
      },
      "source": [
        "print(df_train.describe)\n",
        "print(df_val.describe)\n",
        "print(df_test.describe)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "1562               Raspiy  ...         0\n",
            "15084        Ebony Sealey  ...         1\n",
            "7417   Iindin the Edresia  ...         1\n",
            "12044        Hydee Fisher  ...         1\n",
            "12410       Tanya Ruppell  ...         0\n",
            "...                   ...  ...       ...\n",
            "5191            Mamatha t  ...         0\n",
            "13418             chi mak  ...         0\n",
            "5390      bhawna shraddha  ...         1\n",
            "860       Adrian Anderson  ...         2\n",
            "7270          Alec Machet  ...         0\n",
            "\n",
            "[14171 rows x 12 columns]>\n",
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "1402                Chris  ...         0\n",
            "850          Morhaf Osama  ...         2\n",
            "11028        Girish Palve  ...         0\n",
            "1655         Mauri Galvez  ...         1\n",
            "14287  Jennifer V Mendoza  ...         2\n",
            "...                   ...  ...       ...\n",
            "7234        sventhedog gy  ...         0\n",
            "15641    Arvind Ramshetty  ...         2\n",
            "101          Joe Joejambo  ...         0\n",
            "2342       Janne Uusitalo  ...         2\n",
            "11438  SINGER Somya Yadav  ...         1\n",
            "\n",
            "[787 rows x 12 columns]>\n",
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "6550         Robert Sevin  ...         1\n",
            "14101  Paradoxtal Pythons  ...         1\n",
            "7447        Daniel Whited  ...         1\n",
            "2150                xeigh  ...         2\n",
            "11292  SINGER Somya Yadav  ...         1\n",
            "...                   ...  ...       ...\n",
            "8221         Avesta Irani  ...         2\n",
            "4885            meow meow  ...         0\n",
            "4115      Lucinda Sanchez  ...         1\n",
            "4693          Joshua Choo  ...         2\n",
            "12577            Monica J  ...         1\n",
            "\n",
            "[788 rows x 12 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmPCamhcsr0d"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c62ba7-c510-42ab-d2a9-2d8688f0f194"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGVrAPSTs61N"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f77ce1d-8b24-4f93-d76c-360dc05adb1f"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "5fbb1a5fa9ac4cab9ab1c9ffb0885bd4",
            "eb75e9840d8e449898b97ef67b436a7f",
            "32689e42fe67425589b725df1e447774",
            "66e11e6546f64e408d205bf17e7339f6",
            "0a6fb2417a644d0cb83d48ed65edc709",
            "e83185dd474349589eb0bf95ffb1cad0",
            "ae4adc69d26d4e9e90485ddf05a27b98",
            "bcbd208ab4054e89ac7bd80fb290ab86",
            "a1d12e33408d4197884401c2bb5ad75f",
            "b10f583053254aac81d598a844132afa",
            "09cb1bb65f1942369c5c10578d497c25",
            "ea91a00fa88a42ccb4fcc8f11d737d84",
            "bef3f93d32ca4dcbb87409e3643ef137",
            "eb950df6f61d4ba3bdfc1acd5d1fdba5",
            "06f2f29f4b274f74abce5a2c68b84f84",
            "248adcd92e8043179c77ca7c38232f57"
          ]
        },
        "outputId": "cdfb7006-1f7b-4184-fbec-4a4cb4495e69"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fbb1a5fa9ac4cab9ab1c9ffb0885bd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1d12e33408d4197884401c2bb5ad75f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7TPDTSvTVU"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd171d30-dac7-4d2b-b187-99b8af17e581"
      },
      "source": [
        "# TODO: Q7. Print the sizes of the hidden states and the pooled output.\n",
        "print(last_hidden_state.size())\n",
        "\n",
        "print(pooled_output.size())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 768])\n",
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "device = torch.device('cuda:0')\n",
        "model = model.to(device)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry"
      },
      "source": [
        "outputs1 = model(\n",
        "  input_ids=input_ids,\n",
        "  attention_mask=attention_mask\n",
        ")\n",
        "prob = F.softmax(outputs1, dim=1)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIDtNAE80cIg",
        "outputId": "494c7c2f-5c6a-4307-8047-15d3c56d3367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(prob)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3354, 0.3980, 0.2666],\n",
            "        [0.1757, 0.4797, 0.3446],\n",
            "        [0.3245, 0.4030, 0.2725],\n",
            "        [0.1957, 0.2882, 0.5160],\n",
            "        [0.2358, 0.5754, 0.1887],\n",
            "        [0.2759, 0.1663, 0.5579],\n",
            "        [0.2896, 0.3601, 0.3503],\n",
            "        [0.2124, 0.2239, 0.5638],\n",
            "        [0.3443, 0.3524, 0.3033],\n",
            "        [0.1505, 0.4176, 0.4320],\n",
            "        [0.2504, 0.3261, 0.4234],\n",
            "        [0.2088, 0.3177, 0.4735],\n",
            "        [0.4720, 0.2316, 0.2965],\n",
            "        [0.1548, 0.2498, 0.5954],\n",
            "        [0.2647, 0.3488, 0.3865],\n",
            "        [0.2607, 0.3151, 0.4243]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2-Eu9E6B6n",
        "outputId": "f31781a7-e301-45e3-bea2-d84019689bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print((pred1 == t).sum())"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(7, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNw3sR1wnk3I",
        "outputId": "f159bb64-59ad-41c1-c157-c50dff6e54d8"
      },
      "source": [
        "print(outputs1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3615, -0.1903, -0.5908],\n",
            "        [-0.7786,  0.2256, -0.1051],\n",
            "        [-0.1069,  0.1096, -0.2818],\n",
            "        [-0.4419, -0.0549,  0.5274],\n",
            "        [-0.2578,  0.6342, -0.4805],\n",
            "        [-0.2249, -0.7312,  0.4793],\n",
            "        [-0.2124,  0.0054, -0.0223],\n",
            "        [-0.9187, -0.8659,  0.0577],\n",
            "        [-0.0468, -0.0236, -0.1738],\n",
            "        [-0.8024,  0.2184,  0.2523],\n",
            "        [-0.3920, -0.1279,  0.1332],\n",
            "        [-0.5384, -0.1188,  0.2804],\n",
            "        [ 0.2384, -0.4737, -0.2267],\n",
            "        [-0.6208, -0.1423,  0.7264],\n",
            "        [-0.2993, -0.0235,  0.0792],\n",
            "        [-0.6076, -0.4180, -0.1205]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELFgUQuQv9vK"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqy3d7kF3Ch7"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
        "    \n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions / n_examples, np.mean(losses)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions / n_examples, np.mean(losses)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkeEdYmRr0Zx"
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad894eb-df27-4965-e6be-d5d3e652d28d"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model,train_data_loader,loss_fn,optimizer,device,scheduler,len(df_train))\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(model,val_data_loader,loss_fn,device,len(df_val))\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.6764495525147523 accuracy 0.7151224613189697\n",
            "Val   loss 0.7292031580209732 accuracy 0.6709021329879761\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.6772217202603682 accuracy 0.7167454957962036\n",
            "Val   loss 0.7292031580209732 accuracy 0.6709021329879761\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.6779547213969865 accuracy 0.7158986926078796\n",
            "Val   loss 0.7292031580209732 accuracy 0.6709021329879761\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.6811885882513787 accuracy 0.7127231955528259\n",
            "Val   loss 0.7292031580209732 accuracy 0.6709021329879761\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.6748825839087872 accuracy 0.71625155210495\n",
            "Val   loss 0.7292031580209732 accuracy 0.6709021329879761\n",
            "\n",
            "CPU times: user 19min 13s, sys: 16min 54s, total: 36min 7s\n",
            "Wall time: 36min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V"
      },
      "source": [
        "# TODO: Q11. Plot train/validation accuracies.\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh"
      },
      "source": [
        "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr"
      },
      "source": [
        "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}