{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4prob3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73e3cd5249ca43f18054e789d8b357c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3692809550d649d4b329f4c01f6c13b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c2b950685ee465096668f41cd47e76c",
              "IPY_MODEL_2d0eedf8c1184d02a82c5f8e07249b13"
            ]
          }
        },
        "3692809550d649d4b329f4c01f6c13b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c2b950685ee465096668f41cd47e76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e0e2e5d5c104df4960e0f045a009657",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_118fa53306c742298aefa48fc8de0e40"
          }
        },
        "2d0eedf8c1184d02a82c5f8e07249b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3287fed3c151495cb6c90359ddf31f33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 1.41MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4097827f74f4eaf8c5b6f1b158a2911"
          }
        },
        "9e0e2e5d5c104df4960e0f045a009657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "118fa53306c742298aefa48fc8de0e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3287fed3c151495cb6c90359ddf31f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4097827f74f4eaf8c5b6f1b158a2911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7ad97acb4a64c408db94ac889f6bd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e8892e5a3f046d489a29b9380e1c5a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ebc9379dc36458395ff2e6954a69675",
              "IPY_MODEL_da6468c24d5a4a99a20b430917fc50c0"
            ]
          }
        },
        "5e8892e5a3f046d489a29b9380e1c5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ebc9379dc36458395ff2e6954a69675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9e679a5ce66428c99230a06546f6131",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d832e5a2cf7e434999f0c3b224e74bc6"
          }
        },
        "da6468c24d5a4a99a20b430917fc50c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b108623648a5423fa0137f3149ce7e79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 775B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a703a2fdc2174074925101f5f7fff27c"
          }
        },
        "f9e679a5ce66428c99230a06546f6131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d832e5a2cf7e434999f0c3b224e74bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b108623648a5423fa0137f3149ce7e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a703a2fdc2174074925101f5f7fff27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6f78dc067b049ba9d21057d89d54089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_752fcf2e4a8442df8b982afb960178ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3544e6a0f8374cf597a2ec6194240066",
              "IPY_MODEL_d4b77a5b830040959b708e3c911b59cc"
            ]
          }
        },
        "752fcf2e4a8442df8b982afb960178ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3544e6a0f8374cf597a2ec6194240066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e3117706b36484683ab0c2fb462763b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e999e1b6dc59403d9c0d601de1a9ff84"
          }
        },
        "d4b77a5b830040959b708e3c911b59cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b14fcb4580294d428f92d5b140b50a39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 4.39MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2938dfea8a534747b7928cf400b2dbf7"
          }
        },
        "6e3117706b36484683ab0c2fb462763b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e999e1b6dc59403d9c0d601de1a9ff84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b14fcb4580294d428f92d5b140b50a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2938dfea8a534747b7928cf400b2dbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d818dc2d55c46f08aebf6441f6631c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0146b158ba24ec0a1c971458c4cf4e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cca4ba6613a419bb0d4657c20186bae",
              "IPY_MODEL_075d0d1144514b9f92bdc8e3f06c652f"
            ]
          }
        },
        "e0146b158ba24ec0a1c971458c4cf4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cca4ba6613a419bb0d4657c20186bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7ca9832cb658491e980af84645f44daf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12e2e79aface4d89966f2e75d8a3a452"
          }
        },
        "075d0d1144514b9f92bdc8e3f06c652f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f11a90754d24ec2bc320c2e85de3c62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.99kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23390e3228974e638e3d821db9b7fa85"
          }
        },
        "7ca9832cb658491e980af84645f44daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12e2e79aface4d89966f2e75d8a3a452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f11a90754d24ec2bc320c2e85de3c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23390e3228974e638e3d821db9b7fa85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38308db88f0a4aaab1b61c6e29ed6ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8aa03726fc504588a1d7cd2bc1567d68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a1748c23b694d38aefb6777fb7be899",
              "IPY_MODEL_348413566d9d4886aaed99fdba183914"
            ]
          }
        },
        "8aa03726fc504588a1d7cd2bc1567d68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a1748c23b694d38aefb6777fb7be899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2aa941b8bace4f53afe0473481fbe71e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_698f77cb4fa24ba2a68ced56553565c2"
          }
        },
        "348413566d9d4886aaed99fdba183914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9df0901fa9746d8ad4414a855b06e83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:08&lt;00:00, 51.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffb5fd0f8d7e496391e2fdb2e0712f47"
          }
        },
        "2aa941b8bace4f53afe0473481fbe71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "698f77cb4fa24ba2a68ced56553565c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9df0901fa9746d8ad4414a855b06e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffb5fd0f8d7e496391e2fdb2e0712f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/ECE-GY9123_DL/blob/main/HW/HW4/hw4prob3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66287026-1cac-4391-ccea-e26f021d5dfa"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 19.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 47.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6296931f-68a8-40eb-c5cd-871a483a8c91"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.10\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.8.1+cu101\n",
            "transformers: 4.4.2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15acfd8-bbcc-423f-9e04-88444706f2dd"
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 9.07MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 63.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ofiNmneqeP"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "47f4af13-663a-4d26-c91c-1424d7f800bf"
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiAdQ3j6SDe"
      },
      "source": [
        "Let's first check the size of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c78508-905b-452a-a872-bbacb3784b89"
      },
      "source": [
        "# TODO: Q1. How many samples are there in this dataset? \n",
        "# There are 15746 samples in this dataset\n",
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "99217d36-3dd9-4f9a-94be-676b714535ad"
      },
      "source": [
        "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
        "# we can see that the score of 3 has the most.\n",
        "sns.histplot(data=df['score'],discrete=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1a0ffa2210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk7C5tkJjMiN",
        "outputId": "a6c5cdb3-5f01-4403-d5a8-a507202e00f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    5676\n",
              "1    5042\n",
              "0    5028\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']\n",
        "vals = [5028,5042,5676]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c885b264-5941-41c4-907b-6871e2de2774"
      },
      "source": [
        "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
        "sns.barplot(x=class_names,y=vals)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1a09029810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLO3XSwSkmon"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "73e3cd5249ca43f18054e789d8b357c1",
            "3692809550d649d4b329f4c01f6c13b1",
            "0c2b950685ee465096668f41cd47e76c",
            "2d0eedf8c1184d02a82c5f8e07249b13",
            "9e0e2e5d5c104df4960e0f045a009657",
            "118fa53306c742298aefa48fc8de0e40",
            "3287fed3c151495cb6c90359ddf31f33",
            "e4097827f74f4eaf8c5b6f1b158a2911",
            "b7ad97acb4a64c408db94ac889f6bd9a",
            "5e8892e5a3f046d489a29b9380e1c5a7",
            "0ebc9379dc36458395ff2e6954a69675",
            "da6468c24d5a4a99a20b430917fc50c0",
            "f9e679a5ce66428c99230a06546f6131",
            "d832e5a2cf7e434999f0c3b224e74bc6",
            "b108623648a5423fa0137f3149ce7e79",
            "a703a2fdc2174074925101f5f7fff27c",
            "f6f78dc067b049ba9d21057d89d54089",
            "752fcf2e4a8442df8b982afb960178ce",
            "3544e6a0f8374cf597a2ec6194240066",
            "d4b77a5b830040959b708e3c911b59cc",
            "6e3117706b36484683ab0c2fb462763b",
            "e999e1b6dc59403d9c0d601de1a9ff84",
            "b14fcb4580294d428f92d5b140b50a39",
            "2938dfea8a534747b7928cf400b2dbf7"
          ]
        },
        "outputId": "6dea7006-6e8c-46fa-8af1-d1557d6c2cce"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73e3cd5249ca43f18054e789d8b357c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7ad97acb4a64c408db94ac889f6bd9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6f78dc067b049ba9d21057d89d54089",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5e4476-11cd-4946-ea76-41385c970e04"
      },
      "source": [
        "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
        "print(tokenizer.tokenize(sample_txt))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample_txt)))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56eefea7-e71f-41bf-cde7-a28aa71d7fa4"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511a99b0-9335-4f51-ba23-b00fa5f9ea80"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26abc316-b044-4828-9dc5-7e16f1884921"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48befcc9-46f7-4617-c026-868bd38f82ae"
      },
      "source": [
        "# TODO: Q5. Invert the encoded token ids.\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Every',\n",
              " 'day',\n",
              " 'feels',\n",
              " 'like',\n",
              " 'the',\n",
              " 'same',\n",
              " 'during',\n",
              " 'the',\n",
              " 'lock',\n",
              " 'down',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FssUpW7O7r3E"
      },
      "source": [
        " from torch.utils.data import Dataset"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrxjZ0meZ53"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEO5P7aPnD50",
        "outputId": "81d73a56-dd89-45aa-f8e6-4a57881fe491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO"
      },
      "source": [
        "# TODO: Q6. Create three data frames: df_train, df_val, df_test as above and print their shapes.\n",
        "df_train, test_val = train_test_split(df, test_size=0.1, random_state = 42, shuffle=True)\n",
        "df_val, df_test = train_test_split(test_val, test_size=0.5,random_state = 43, shuffle=True)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1n6rbTnhpU",
        "outputId": "d5cf6179-739f-4eb5-8ded-2796e8e020f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df_train.describe)\n",
        "print(df_val.describe)\n",
        "print(df_test.describe)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.describe of                  userName  ... sentiment\n",
            "1562               Raspiy  ...         0\n",
            "15084        Ebony Sealey  ...         1\n",
            "7417   Iindin the Edresia  ...         1\n",
            "12044        Hydee Fisher  ...         1\n",
            "12410       Tanya Ruppell  ...         0\n",
            "...                   ...  ...       ...\n",
            "5191            Mamatha t  ...         0\n",
            "13418             chi mak  ...         0\n",
            "5390      bhawna shraddha  ...         1\n",
            "860       Adrian Anderson  ...         2\n",
            "7270          Alec Machet  ...         0\n",
            "\n",
            "[14171 rows x 12 columns]>\n",
            "<bound method NDFrame.describe of               userName  ... sentiment\n",
            "6321          Nam Phan  ...         0\n",
            "3617   Travis Richards  ...         0\n",
            "12002  Y0ur_Mockingjay  ...         0\n",
            "12222        Orel Levy  ...         0\n",
            "2483       Scott Paris  ...         0\n",
            "...                ...  ...       ...\n",
            "4772       Angie Ramos  ...         2\n",
            "2677       Ryland Hall  ...         0\n",
            "19      Maezielyn Ware  ...         0\n",
            "11991          Holly T  ...         0\n",
            "2189        Greg Simms  ...         2\n",
            "\n",
            "[787 rows x 12 columns]>\n",
            "<bound method NDFrame.describe of                    userName  ... sentiment\n",
            "14189         Brian Gilbert  ...         2\n",
            "4081   Color Coded Creature  ...         1\n",
            "11948      kashish bhardwaj  ...         2\n",
            "15711         A Google user  ...         2\n",
            "6557                 Mujgan  ...         1\n",
            "...                     ...  ...       ...\n",
            "5601                 hlya h  ...         2\n",
            "8498             Regi Adams  ...         0\n",
            "8443        Jaymes Williams  ...         0\n",
            "11481         A Google user  ...         1\n",
            "491                カシャニニッキー  ...         1\n",
            "\n",
            "[788 rows x 12 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmPCamhcsr0d"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI",
        "outputId": "66daeac2-44bf-4088-ad8d-088a45e4edf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGVrAPSTs61N"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "outputId": "898797a4-fab1-407a-89a1-1063f43ff58d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI",
        "outputId": "7d1fa3f8-8e38-4849-852c-1b2b0374658b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "5d818dc2d55c46f08aebf6441f6631c8",
            "e0146b158ba24ec0a1c971458c4cf4e8",
            "9cca4ba6613a419bb0d4657c20186bae",
            "075d0d1144514b9f92bdc8e3f06c652f",
            "7ca9832cb658491e980af84645f44daf",
            "12e2e79aface4d89966f2e75d8a3a452",
            "5f11a90754d24ec2bc320c2e85de3c62",
            "23390e3228974e638e3d821db9b7fa85",
            "38308db88f0a4aaab1b61c6e29ed6ad3",
            "8aa03726fc504588a1d7cd2bc1567d68",
            "7a1748c23b694d38aefb6777fb7be899",
            "348413566d9d4886aaed99fdba183914",
            "2aa941b8bace4f53afe0473481fbe71e",
            "698f77cb4fa24ba2a68ced56553565c2",
            "a9df0901fa9746d8ad4414a855b06e83",
            "ffb5fd0f8d7e496391e2fdb2e0712f47"
          ]
        }
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d818dc2d55c46f08aebf6441f6631c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38308db88f0a4aaab1b61c6e29ed6ad3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7TPDTSvTVU"
      },
      "source": [
        "output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask'],\n",
        ")\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "outputId": "667a8305-ab40-43e6-ac95-30cdee76ab60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q7. Print the sizes of the hidden states and the pooled output.\n",
        "print(output.last_hidden_state.shape)\n",
        "\n",
        "print(output.pooler_output.shape)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 768])\n",
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "device = torch.device('cuda:0')\n",
        "model = model.to(device)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry",
        "outputId": "8d40c1b8-881c-4ed8-9882-508ffd9397e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "outputs1 = model(\n",
        "  input_ids=input_ids,\n",
        "  attention_mask=attention_mask\n",
        ")\n",
        "prob = F.softmax(outputs1, dim=1)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-b83d38fdc3a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m outputs1 = model(\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-64dc92491dcb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dropout(): argument 'input' (position 1) must be Tensor, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
        "    \n",
        "    input_ids = \n",
        "    attention_mask = \n",
        "    targets = \n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += \n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
        "\n",
        "  train_acc, train_loss = \n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = \n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V"
      },
      "source": [
        "# TODO: Q11. Plot train/validation accuracies."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh"
      },
      "source": [
        "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr"
      },
      "source": [
        "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}