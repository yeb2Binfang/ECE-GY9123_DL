{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4prob3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5be955a591974ffda8af953a6c500d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b8f51617addb437095d3e47dfb9d5bbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e5d3b44aa7849e0bac6bb24d53992e5",
              "IPY_MODEL_c82525c0a22d4b3ea61b1274fee6b940"
            ]
          }
        },
        "b8f51617addb437095d3e47dfb9d5bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e5d3b44aa7849e0bac6bb24d53992e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a67f53859ec418285b91d99c51b64b8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a3eb72bf9a54d9b87cc9ec18fc13bb3"
          }
        },
        "c82525c0a22d4b3ea61b1274fee6b940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26d2a2489f834675ba090660fbf1a557",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 538kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aef0570d7baf4c77854732d1c0465630"
          }
        },
        "1a67f53859ec418285b91d99c51b64b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a3eb72bf9a54d9b87cc9ec18fc13bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26d2a2489f834675ba090660fbf1a557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aef0570d7baf4c77854732d1c0465630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "963c0cc180654e48945bd3afbb854a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a0e8841b9b74135b8db7b4e9653ee70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77afdc9ac3504f1ba884e01afc300d16",
              "IPY_MODEL_d76bfac57ab744a990fe4b19e9f4f547"
            ]
          }
        },
        "9a0e8841b9b74135b8db7b4e9653ee70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77afdc9ac3504f1ba884e01afc300d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a867155d26d546eb962242d270aecee5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c46c8e650e4e4e19873cd0461a1c170e"
          }
        },
        "d76bfac57ab744a990fe4b19e9f4f547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db201349cdb24024baf45fcd5fe845cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 36.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b953358a0d044abb548b359f303a4d8"
          }
        },
        "a867155d26d546eb962242d270aecee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c46c8e650e4e4e19873cd0461a1c170e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db201349cdb24024baf45fcd5fe845cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b953358a0d044abb548b359f303a4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1782d588f89d410f964bf9580759f9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5105a75b0286408685d365520fc967d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14e62cef2c6849d99fa50a953e4699b9",
              "IPY_MODEL_fc5adb4c4a914dfbb64d05553e50e6d4"
            ]
          }
        },
        "5105a75b0286408685d365520fc967d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14e62cef2c6849d99fa50a953e4699b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8bfaec76ef6f4a5d8fac322e31521167",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8466ba6ffa2e4fc3955fdc15d2a40c53"
          }
        },
        "fc5adb4c4a914dfbb64d05553e50e6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f9876e159d44cf383a41c2a0a7c2372",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 1.28MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4151cbaa8514a0bbbab361110fd7eff"
          }
        },
        "8bfaec76ef6f4a5d8fac322e31521167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8466ba6ffa2e4fc3955fdc15d2a40c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f9876e159d44cf383a41c2a0a7c2372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4151cbaa8514a0bbbab361110fd7eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/ECE-GY9123_DL/blob/main/HW/HW4/hw4prob3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM",
        "outputId": "2a965aa7-f368-4586-e8f5-0f2380cb8d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 44.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "outputId": "124edf47-c9de-4a86-d0e9-ed2b1a8edb6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.10\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.8.0+cu101\n",
            "transformers: 4.4.2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "outputId": "6ab41bf4-dad8-4ea2-cc1b-e88c865dc462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 49.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 113MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ofiNmneqeP"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "outputId": "daaf8f9c-77d9-4a8e-9daa-e31957da7fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiAdQ3j6SDe"
      },
      "source": [
        "Let's first check the size of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "outputId": "ac7d1ab2-3b37-4613-ac01-00a112e50b83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q1. How many samples are there in this dataset? \n",
        "# There are 15746 samples in this dataset\n",
        "df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "outputId": "3f19188c-841d-4dc2-99b7-fd16cd3141a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
        "# we can see that the score of 3 has the most.\n",
        "sns.histplot(data=df['score'],discrete=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd1b29a3b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "outputId": "093eafaf-276c-4b57-e2d4-87bd767ed963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
        "sns.histplot(data=df['sentiment'],discrete=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd1b2889590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUWklEQVR4nO3df9TedX3f8edLAuhRK0HSlIbQ4CFbi3pEmvKz20HpENlqaIeIp0cCw8Wt2Om6dcV2p5yqnEG3SWt/oDnCMTjHj1kdwVFZyg+7zYIERRCoJVJZEhAiQdQx6YLv/XF9br0I953PlXBf94/cz8c517m+38/38/1+359cyf3K98f1vVNVSJK0Oy+a7QIkSXOfYSFJ6jIsJEldhoUkqcuwkCR1LZrtAsbhkEMOqRUrVsx2GZI0r9x1113fqqolky3bJ8NixYoVbNq0abbLkKR5JcnDUy3zNJQkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlrn/wGt6TxW7b8cB7ZumW2y9AufvKw5Wzb8r+nfbuGhaS98sjWLbzto1+Y7TK0i2vfdeJYtutpKElSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldYw2LJN9Icm+Su5Nsam0HJ9mY5MH2vri1J8mHk2xOck+SY4a2s6b1fzDJmnHWLEl6vpk4snhDVR1dVava/IXAzVW1Eri5zQO8GVjZXmuBy2EQLsBFwHHAscBFEwEjSZoZi2Zhn6uBk9v0euA24Ddb+1VVVcDtSQ5Kcmjru7GqdgAk2QicBlw9rgKXLT+cR7ZuGdfmtRf22/9Anv1/z8x2GdKCNe6wKOC/Jyngo1W1DlhaVY+25d8ElrbpZcDwT+itrW2q9udIspbBEQmHH374Cyr6ka1beNtHv/CCtqHpde27TvQzmWOufdeJs12CZtC4w+Lnq2pbkh8HNib5q+GFVVUtSF6wFkTrAFatWjUt25QkDYz1mkVVbWvvjwOfYXDN4bF2eon2/njrvg1YPrT6Ya1tqnZJ0gwZW1gkeWmSl09MA6cCXwU2ABN3NK0Brm/TG4Bz2l1RxwNPtdNVNwGnJlncLmyf2tokSTNknKehlgKfSTKxn/9cVZ9LcidwXZLzgYeBs1r/G4HTgc3A08B5AFW1I8kHgDtbv/dPXOyWJM2MsYVFVT0EvG6S9ieAUyZpL+CCKbZ1JXDldNcoSRqN3+CWJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSusYeFkn2S/LlJJ9t80ckuSPJ5iTXJjmgtR/Y5je35SuGtvG+1v61JG8ad82SpOeaiSOL9wAPDM1fClxWVUcCTwLnt/bzgSdb+2WtH0mOAs4GXg2cBvxJkv1moG5JUjPWsEhyGPAPgY+1+QBvBD7VuqwHzmjTq9s8bfkprf9q4Jqqeqaq/gbYDBw7zrolSc817iOL3wf+DfCDNv9K4NtVtbPNbwWWtellwBaAtvyp1v+H7ZOs80NJ1ibZlGTT9u3bp3sckrSgjS0skvwj4PGqumtc+xhWVeuqalVVrVqyZMlM7FKSFoxFY9z2ScBbkpwOvBj4MeAPgIOSLGpHD4cB21r/bcByYGuSRcArgCeG2icMryNJmgFjO7KoqvdV1WFVtYLBBepbqupXgFuBM1u3NcD1bXpDm6ctv6WqqrWf3e6WOgJYCXxxXHVLkp5vnEcWU/lN4JokHwS+DFzR2q8APpFkM7CDQcBQVfcluQ64H9gJXFBVz8582ZK0cM1IWFTVbcBtbfohJrmbqaq+D7x1ivUvBi4eX4WSpN3xG9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSukYKiyQnjdImSdo3jXpk8YcjtkmS9kGLdrcwyQnAicCSJL8+tOjHgP3GWZgkae7YbVgABwAva/1ePtT+HeDMcRUlSZpbdhsWVfV54PNJPl5VD89QTZKkOaZ3ZDHhwCTrgBXD61TVG8dRlCRpbhk1LP4L8BHgY8Cz4ytHkjQXjRoWO6vq8rFWIkmas0a9dfaGJL+a5NAkB0+8drdCkhcn+WKSryS5L8nvtvYjktyRZHOSa5Mc0NoPbPOb2/IVQ9t6X2v/WpI37eVYJUl7adSwWAP8BvAF4K722tRZ5xngjVX1OuBo4LQkxwOXApdV1ZHAk8D5rf/5wJOt/bLWjyRHAWcDrwZOA/4kibftStIMGiksquqISV6v6qxTVfW9Nrt/exXwRuBTrX09cEabXt3mactPSZLWfk1VPVNVfwNsBo4dcXySpGkw0jWLJOdM1l5VV3XW24/BUciRwB8DXwe+XVU7W5etwLI2vQzY0ra7M8lTwCtb++1Dmx1eZ3hfa4G1AIcffvgow5IkjWjUC9w/NzT9YuAU4EvAbsOiqp4Fjk5yEPAZ4Kf3pshRVNU6YB3AqlWralz7kaSFaKSwqKpfG55vP/yvGXUnVfXtJLcCJwAHJVnUji4OA7a1btuA5cDWJIuAVwBPDLVPGF5HkjQD9vYR5f8HOGJ3HZIsaaFCkpcA/wB4ALiVHz0qZA1wfZve0OZpy2+pqmrtZ7e7pY4AVgJf3Mu6JUl7YdRrFjcwuDgNgwcI/gxwXWe1Q4H17brFi4DrquqzSe4HrknyQeDLwBWt/xXAJ5JsBnYwuAOKqrovyXXA/cBO4IJ2ekuSNENGvWbxH4amdwIPV9XW3a1QVfcAr5+k/SEmuZupqr4PvHWKbV0MXDxirZKkaTbqrbOfB/6KwZNnFwN/O86iJElzy6i/Ke8sBtcJ3gqcBdyRxEeUS9ICMeppqN8Gfq6qHofBxWvgz/nRl+skSfuwUe+GetFEUDRP7MG6kqR5btQji88luQm4us2/DbhxPCVJkuaa3u/gPhJYWlW/keSXgZ9vi/4S+OS4i5MkzQ29I4vfB94HUFWfBj4NkOS1bdkvjrU6SdKc0LvusLSq7t21sbWtGEtFkqQ5pxcWB+1m2UumsxBJ0tzVC4tNSf7pro1J3sng0eOSpAWgd83ivcBnkvwKPwqHVcABwC+NszBJ0tyx27CoqseAE5O8AXhNa/5vVXXL2CuTJM0Zo/4+i1sZPFpckrQA+S1sSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1DW2sEiyPMmtSe5Pcl+S97T2g5NsTPJge1/c2pPkw0k2J7knyTFD21rT+j+YZM24apYkTW6cRxY7gX9VVUcBxwMXJDkKuBC4uapWAje3eYA3Ayvbay1wOQzCBbgIOA44FrhoImAkSTNjbGFRVY9W1Zfa9HeBB4BlwGpgfeu2HjijTa8GrqqB24GDkhwKvAnYWFU7qupJYCNw2rjqliQ934xcs0iyAng9cAewtKoebYu+CSxt08uALUOrbW1tU7Xvuo+1STYl2bR9+/ZprV+SFrqxh0WSlwF/Cry3qr4zvKyqCqjp2E9VrauqVVW1asmSJdOxSUlSM9awSLI/g6D4ZFV9ujU/1k4v0d4fb+3bgOVDqx/W2qZqlyTNkHHeDRXgCuCBqvrQ0KINwMQdTWuA64faz2l3RR0PPNVOV90EnJpkcbuwfWprkyTNkEVj3PZJwDuAe5Pc3dp+C7gEuC7J+cDDwFlt2Y3A6cBm4GngPICq2pHkA8Cdrd/7q2rHGOuWJO1ibGFRVf8TyBSLT5mkfwEXTLGtK4Erp686SdKe8BvckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6xhYWSa5M8niSrw61HZxkY5IH2/vi1p4kH06yOck9SY4ZWmdN6/9gkjXjqleSNLVxHll8HDhtl7YLgZuraiVwc5sHeDOwsr3WApfDIFyAi4DjgGOBiyYCRpI0c8YWFlX1F8COXZpXA+vb9HrgjKH2q2rgduCgJIcCbwI2VtWOqnoS2MjzA0iSNGYzfc1iaVU92qa/CSxt08uALUP9tra2qdqfJ8naJJuSbNq+ffv0Vi1JC9ysXeCuqgJqGre3rqpWVdWqJUuWTNdmJUnMfFg81k4v0d4fb+3bgOVD/Q5rbVO1S5Jm0EyHxQZg4o6mNcD1Q+3ntLuijgeeaqerbgJOTbK4Xdg+tbVJkmbQonFtOMnVwMnAIUm2Mrir6RLguiTnAw8DZ7XuNwKnA5uBp4HzAKpqR5IPAHe2fu+vql0vmkuSxmxsYVFVb59i0SmT9C3ggim2cyVw5TSWJknaQ36DW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeqaN2GR5LQkX0uyOcmFs12PJC0k8yIskuwH/DHwZuAo4O1JjprdqiRp4ZgXYQEcC2yuqoeq6m+Ba4DVs1yTJC0YqarZrqEryZnAaVX1zjb/DuC4qnr3UJ+1wNo2+3eBr72AXR4CfOsFrD9X7CvjAMcyF+0r4wDHMuGnqmrJZAsW7X09c0tVrQPWTce2kmyqqlXTsa3ZtK+MAxzLXLSvjAMcyyjmy2mobcDyofnDWpskaQbMl7C4E1iZ5IgkBwBnAxtmuSZJWjDmxWmoqtqZ5N3ATcB+wJVVdd8Ydzktp7PmgH1lHOBY5qJ9ZRzgWLrmxQVuSdLsmi+noSRJs8iwkCR1GRZAkoOTbEzyYHtfPEW/Z5Pc3V5z5gJ771EoSQ5Mcm1bfkeSFTNf5WhGGMu5SbYPfQ7vnI06e5JcmeTxJF+dYnmSfLiN854kx8x0jaMaYSwnJ3lq6DP5nZmucRRJlie5Ncn9Se5L8p5J+syLz2XEsUzv51JVC/4F/B5wYZu+ELh0in7fm+1aJ6lpP+DrwKuAA4CvAEft0udXgY+06bOBa2e77hcwlnOBP5rtWkcYy98HjgG+OsXy04E/AwIcD9wx2zW/gLGcDHx2tuscYRyHAse06ZcDfz3J36958bmMOJZp/Vw8shhYDaxv0+uBM2axlj01yqNQhsf3KeCUJJnBGke1zzzWpar+Atixmy6rgatq4HbgoCSHzkx1e2aEscwLVfVoVX2pTX8XeABYtku3efG5jDiWaWVYDCytqkfb9DeBpVP0e3GSTUluTzJXAmUZsGVofivP/0vzwz5VtRN4CnjljFS3Z0YZC8A/bqcIPpVk+STL54NRxzpfnJDkK0n+LMmrZ7uYnnYq9vXAHbssmnefy27GAtP4ucyL71lMhyR/DvzEJIt+e3imqirJVPcT/1RVbUvyKuCWJPdW1denu1bt1g3A1VX1TJJ3MThieuMs17TQfYnBv43vJTkd+K/AylmuaUpJXgb8KfDeqvrObNfzQnTGMq2fy4I5sqiqX6iq10zyuh54bOJQs70/PsU2trX3h4DbGKT5bBvlUSg/7JNkEfAK4IkZqW7PdMdSVU9U1TNt9mPAz85QbdNtn3mETVV9p6q+16ZvBPZPcsgslzWpJPsz+OH6yar69CRd5s3n0hvLdH8uCyYsOjYAa9r0GuD6XTskWZzkwDZ9CHAScP+MVTi1UR6FMjy+M4Fbql0Bm2O6Y9nl/PFbGJyrnY82AOe0u2+OB54aOhU6ryT5iYlrYEmOZfBzZc79Z6TVeAXwQFV9aIpu8+JzGWUs0/25LJjTUB2XANclOR94GDgLIMkq4J/V4NHoPwN8NMkPGPyhX1JVsx4WNcWjUJK8H9hUVRsY/KX6RJLNDC5Unj17FU9txLH8iyRvAXYyGMu5s1bwbiS5msHdKIck2QpcBOwPUFUfAW5kcOfNZuBp4LzZqbRvhLGcCfzzJDuB/wucPUf/M3IS8A7g3iR3t7bfAg6Hefe5jDKWaf1cfNyHJKnL01CSpC7DQpLUZVhIkroMC0lSl2EhSeoyLKRpluTo9o3Zifm3ZJIn6E7zPk9OcuI496GFzbCQpt/RDO7VB6CqNlTVJWPe58mAYaGx8XsW0pAkLwWuY/CYh/2ADzD4gtaHgJcB3wLOrapHk9zG4OFtbwAOAs5v85uBlzB4TMS/a9OrqurdST7O4AtSrwd+HPgnwDnACQweh31uq+NU4HeBAxk8tv289oyfbzB4HtYvMvhi3FuB7wO3A88C24Ffq6r/MY4/Hy1cHllIz3Ua8EhVva6qXgN8DvhD4Myq+lngSuDiof6LqupY4L3ARe3R6r/D4HeGHF1V106yj8UMwuFfMni8xGXAq4HXtlNYhwD/FviFqjoG2AT8+tD632rtlwP/uqq+AXwEuKzt06DQtPNxH9Jz3Qv8xySXAp8FngReA2xsj9nZDxh+VtDEA9zuAlaMuI8b2tON7wUeq6p7AZLc17ZxGHAU8L/aPg8A/nKKff7yHoxN2muGhTSkqv66/SrN04EPArcA91XVCVOsMvEE3GcZ/d/TxDo/GJqemF/UtrWxqt4+jfuUXhBPQ0lDkvwk8HRV/Sfg3wPHAUuSnNCW7z/CL5H5LoNfdbm3bgdOSnJk2+dLk/ydMe9T2i3DQnqu1wJfbE/yvIjB9YczgUuTfAW4m/5dR7cCRyW5O8nb9rSAqtrO4Gm6Vye5h8EpqJ/urHYD8Ettn39vT/cp9Xg3lCSpyyMLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLU9f8Bg10lesE3rroAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLO3XSwSkmon"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF",
        "outputId": "41dfbbef-990a-45b9-9265-ab80dba8f564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "5be955a591974ffda8af953a6c500d4b",
            "b8f51617addb437095d3e47dfb9d5bbd",
            "1e5d3b44aa7849e0bac6bb24d53992e5",
            "c82525c0a22d4b3ea61b1274fee6b940",
            "1a67f53859ec418285b91d99c51b64b8",
            "1a3eb72bf9a54d9b87cc9ec18fc13bb3",
            "26d2a2489f834675ba090660fbf1a557",
            "aef0570d7baf4c77854732d1c0465630",
            "963c0cc180654e48945bd3afbb854a14",
            "9a0e8841b9b74135b8db7b4e9653ee70",
            "77afdc9ac3504f1ba884e01afc300d16",
            "d76bfac57ab744a990fe4b19e9f4f547",
            "a867155d26d546eb962242d270aecee5",
            "c46c8e650e4e4e19873cd0461a1c170e",
            "db201349cdb24024baf45fcd5fe845cb",
            "9b953358a0d044abb548b359f303a4d8",
            "1782d588f89d410f964bf9580759f9e1",
            "5105a75b0286408685d365520fc967d9",
            "14e62cef2c6849d99fa50a953e4699b9",
            "fc5adb4c4a914dfbb64d05553e50e6d4",
            "8bfaec76ef6f4a5d8fac322e31521167",
            "8466ba6ffa2e4fc3955fdc15d2a40c53",
            "0f9876e159d44cf383a41c2a0a7c2372",
            "f4151cbaa8514a0bbbab361110fd7eff"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5be955a591974ffda8af953a6c500d4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "963c0cc180654e48945bd3afbb854a14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1782d588f89d410f964bf9580759f9e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "outputId": "af5c4f0b-ab0e-4cbb-e48d-b281276d2893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
        "print(tokenizer.tokenize(sample_txt))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample_txt)))\n",
        "print(tokenizer.convert_tokens_to_ids(sample_txt))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "outputId": "bef4ead0-27fc-40da-fff4-b71cbac4fbb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "outputId": "f9d88e71-c7b4-45a3-de84-d014ef2df566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "outputId": "66ebd6df-75b0-4cbf-e202-5582571f9778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "outputId": "6b88cf84-6877-4a87-da50-f073989ee0a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q5. Invert the encoded token ids.\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Every',\n",
              " 'day',\n",
              " 'feels',\n",
              " 'like',\n",
              " 'the',\n",
              " 'same',\n",
              " 'during',\n",
              " 'the',\n",
              " 'lock',\n",
              " 'down',\n",
              " '.',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0",
        "outputId": "a5bf81d2-d0dd-48d4-92ee-58d833a398b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-cb3ac03ca3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGPReviewDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_validate_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\" validate the passed dtype \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# a compound dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0;31m# raise a consistent TypeError if failed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m         \u001b[0mnpdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mSyntaxError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;31m# np.dtype uses `eval` which can raise SyntaxError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_usefields\u001b[0;34m(adict, align)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_makenames_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mformats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_makenames_list\u001b[0;34m(adict, align)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entry not a 2- or 3- tuple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: entry not a 2- or 3- tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO"
      },
      "source": [
        "# TODO: Q6. Create three data frames: df_train, df_val, df_test as above and print their shapes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1aoFxbQSn15"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci"
      },
      "source": [
        "# TODO: Q7. Print the sizes of the hidden states and the pooled output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry"
      },
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
        "    \n",
        "    input_ids = \n",
        "    attention_mask = \n",
        "    targets = \n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += \n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
        "\n",
        "  train_acc, train_loss = \n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = \n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V"
      },
      "source": [
        "# TODO: Q11. Plot train/validation accuracies."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh"
      },
      "source": [
        "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr"
      },
      "source": [
        "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}